{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "633b614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "split = 0.125\n",
    "#train=df.sample(frac=0.8,random_state=200)\n",
    "#test=df.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afa08ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID      DOCULECT CONCEPT     IPA      TOKENS  COGID  \\\n",
      "0      263         Erzya      at  kedʲse  k e dʲ s e   2340   \n",
      "1      264         Erzya      at    peʎe     p e ʎ e   2343   \n",
      "2      277       Ingrian      at    loːn      l oː n   2338   \n",
      "3      282  Komi-Permyak      at   sɑjɯn   s ɑ j ɯ n   2348   \n",
      "4      283  Komi-Permyak      at   dɯnɯn   d ɯ n ɯ n   2351   \n",
      "..     ...           ...     ...     ...         ...    ...   \n",
      "167  10179      Nganasan      we     mɯŋ       m ɯ ŋ   3499   \n",
      "168  10166       Ingrian      we     møː        m øː   3499   \n",
      "169  10171   Komi-Zyrian      we      mi         m i   3499   \n",
      "170  10192        Selkup      we     meː        m eː   3499   \n",
      "171  10201        Udmurt      we      mi         m i   3499   \n",
      "\n",
      "    SOURCE_COGNATE_CLASS                  CLPA  CONCEPTICON_ID GLOTTOLOG  \n",
      "0                 U-at-e  838 1089 129 89 1089            1461  erzy1239  \n",
      "1                 U-at-h     291 1089 588 1089            1461  erzy1239  \n",
      "2                 U-at-a           554 880 107            1461  ingr1248  \n",
      "3                 U-at-s    89 952 570 944 107            1461  komi1269  \n",
      "4                 U-at-w   145 944 107 944 107            1461  komi1269  \n",
      "..                   ...                   ...             ...       ...  \n",
      "167               U-we-a           241 944 801            1212  ngan1291  \n",
      "168               U-we-a              241 1050            1212  ingr1248  \n",
      "169               U-we-a              241 1076            1212  komi1268  \n",
      "170               U-we-a              241 1091            1212  selk1253  \n",
      "171               U-we-a              241 1076            1212  udmu1245  \n",
      "\n",
      "[172 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DOCULECT iso_code CONCEPT concepticon_id      IPA        TOKENS  \\\n",
      "0      Greek_Anc      grc   ashes                  spódos   s p ó d o s   \n",
      "1      Greek_Anc      grc   ashes                 tépʰraː   t é pʰ r aː   \n",
      "2      Greek_Anc      grc   ashes                  kóniːs    k ó n iː s   \n",
      "3      Greek_Mod      ell   ashes                 ˈte̞fra   ˈt e̞ f r a   \n",
      "4      Greek_Mod      ell   ashes                 ˈstaxti  ˈs t a x t i   \n",
      "...          ...      ...     ...            ...      ...           ...   \n",
      "1208  Portuguese      por    worm                  ˈvɛɾmɨ    ˈv ɛ ɾ m ɨ   \n",
      "1209     Spanish      spa    worm                  gusano   g u s a n o   \n",
      "1210      French      fra    worm                     vɛʀ         v ɛ ʀ   \n",
      "1211     Italian      ita    worm                   vɛrme     v ɛ r m e   \n",
      "1212   Old_Irish      sga    worm                   kruṽʹ      k r u ṽʹ   \n",
      "\n",
      "         asjp        dolgo          sca   cog_id  COGID  \n",
      "0      spodos  S P V T V S  S P U T U S  ashes:B     35  \n",
      "1     teph~ra    T V P R V    T E P R A  ashes:L     41  \n",
      "2       konis    K V N V S    K U N I S  ashes:U     45  \n",
      "3       tefra    T V P R V    T E B R A  ashes:L     41  \n",
      "4      staxti  S T V K T V  S T A G T I  ashes:H     39  \n",
      "...       ...          ...          ...      ...    ...  \n",
      "1208    vErm3    W V R M V    B E R M I   worm:B   2121  \n",
      "1209   gusano  K V S V N V  K Y S A N U   worm:G   2125  \n",
      "1210      vEr        W V R        B E R   worm:B   2121  \n",
      "1211    vErme    W V R M V    B E R M E   worm:B   2121  \n",
      "1212      kru      K R V W      K R Y W   worm:A   2120  \n",
      "\n",
      "[1213 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for fold in ['test1', 'test2']:\n",
    "    files = os.listdir(fold)\n",
    "    for file in tqdm(files):\n",
    "        for i in range(5):\n",
    "            df = pd.read_csv(os.path.join(fold,file), sep= '\\t')\n",
    "            df.dropna(subset=['DOCULECT'], inplace=True)\n",
    "            df.fillna('',inplace=True)\n",
    "            concept = pd.DataFrame(df['CONCEPT'].unique(), columns=['CONCEPT']).dropna()\n",
    "            train=concept.sample(frac=split,random_state=200*i)\n",
    "            test=concept.drop(train.index)\n",
    "            train = df.merge(train)\n",
    "            test = df.merge(test)\n",
    "            type_dict = {}\n",
    "            for col, typ in df.dtypes.items():\n",
    "                if typ == 'float64':\n",
    "                    type_dict[col] = 'int64'\n",
    "            train = train.astype(type_dict)\n",
    "            test = test.astype(type_dict)\n",
    "            save_dir = f\"split_{i}\"\n",
    "            train_pth = os.path.join(save_dir,'train')\n",
    "            test_pth = os.path.join(save_dir,'test')\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.mkdir(save_dir)\n",
    "                os.mkdir(train_pth)\n",
    "                os.mkdir(test_pth)\n",
    "            f_name = file.split('.csv')[0]\n",
    "            train.to_csv(os.path.join(train_pth,f\"{f_name}_train.csv\"), sep= '\\t', index= False)\n",
    "            test.to_csv(os.path.join(test_pth,f\"{f_name}_test.csv\"), sep= '\\t', index= False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159818e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
